{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012e9753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19158 entries, 0 to 19157\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             19158 non-null  int64  \n",
      " 1   city                    19158 non-null  object \n",
      " 2   city_development_index  19158 non-null  float64\n",
      " 3   gender                  14650 non-null  object \n",
      " 4   relevent_experience     19158 non-null  object \n",
      " 5   enrolled_university     18772 non-null  object \n",
      " 6   education_level         18698 non-null  object \n",
      " 7   major_discipline        16345 non-null  object \n",
      " 8   experience              19093 non-null  object \n",
      " 9   company_size            13220 non-null  object \n",
      " 10  company_type            13018 non-null  object \n",
      " 11  last_new_job            18735 non-null  object \n",
      " 12  training_hours          19158 non-null  int64  \n",
      " 13  target                  19158 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "268212\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"../data/aug_train.csv\")\n",
    "\n",
    "print(train.info())\n",
    "print(train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ec1a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['enrollee_id', 'city', 'city_development_index', 'gender',\n",
      "       'relevent_experience', 'enrolled_university', 'education_level',\n",
      "       'major_discipline', 'experience', 'company_size', 'company_type',\n",
      "       'last_new_job', 'training_hours', 'target'],\n",
      "      dtype='object')\n",
      "   enrollee_id      city  city_development_index gender  \\\n",
      "0         8949  city_103                   0.920   Male   \n",
      "1        29725   city_40                   0.776   Male   \n",
      "2        11561   city_21                   0.624    NaN   \n",
      "3        33241  city_115                   0.789    NaN   \n",
      "4          666  city_162                   0.767   Male   \n",
      "\n",
      "       relevent_experience enrolled_university education_level  \\\n",
      "0  Has relevent experience       no_enrollment        Graduate   \n",
      "1   No relevent experience       no_enrollment        Graduate   \n",
      "2   No relevent experience    Full time course        Graduate   \n",
      "3   No relevent experience                 NaN        Graduate   \n",
      "4  Has relevent experience       no_enrollment         Masters   \n",
      "\n",
      "  major_discipline experience company_size    company_type last_new_job  \\\n",
      "0             STEM        >20          NaN             NaN            1   \n",
      "1             STEM         15        50-99         Pvt Ltd           >4   \n",
      "2             STEM          5          NaN             NaN        never   \n",
      "3  Business Degree         <1          NaN         Pvt Ltd        never   \n",
      "4             STEM        >20        50-99  Funded Startup            4   \n",
      "\n",
      "   training_hours  target  \n",
      "0              36     1.0  \n",
      "1              47     0.0  \n",
      "2              83     0.0  \n",
      "3              52     1.0  \n",
      "4               8     0.0  \n",
      "       enrollee_id      city  city_development_index gender  \\\n",
      "19153         7386  city_173                   0.878   Male   \n",
      "19154        31398  city_103                   0.920   Male   \n",
      "19155        24576  city_103                   0.920   Male   \n",
      "19156         5756   city_65                   0.802   Male   \n",
      "19157        23834   city_67                   0.855    NaN   \n",
      "\n",
      "           relevent_experience enrolled_university education_level  \\\n",
      "19153   No relevent experience       no_enrollment        Graduate   \n",
      "19154  Has relevent experience       no_enrollment        Graduate   \n",
      "19155  Has relevent experience       no_enrollment        Graduate   \n",
      "19156  Has relevent experience       no_enrollment     High School   \n",
      "19157   No relevent experience       no_enrollment  Primary School   \n",
      "\n",
      "      major_discipline experience company_size company_type last_new_job  \\\n",
      "19153       Humanities         14          NaN          NaN            1   \n",
      "19154             STEM         14          NaN          NaN            4   \n",
      "19155             STEM        >20        50-99      Pvt Ltd            4   \n",
      "19156              NaN         <1      500-999      Pvt Ltd            2   \n",
      "19157              NaN          2          NaN          NaN            1   \n",
      "\n",
      "       training_hours  target  \n",
      "19153              42     1.0  \n",
      "19154              52     1.0  \n",
      "19155              44     0.0  \n",
      "19156              97     0.0  \n",
      "19157             127     0.0  \n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(train.head())\n",
    "print(train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2cdce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enrollee_id                  0\n",
      "city                         0\n",
      "city_development_index       0\n",
      "gender                    4508\n",
      "relevent_experience          0\n",
      "enrolled_university        386\n",
      "education_level            460\n",
      "major_discipline          2813\n",
      "experience                  65\n",
      "company_size              5938\n",
      "company_type              6140\n",
      "last_new_job               423\n",
      "training_hours               0\n",
      "target                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab38322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enrollee_id               0\n",
      "city                      0\n",
      "city_development_index    0\n",
      "gender                    0\n",
      "relevent_experience       0\n",
      "enrolled_university       0\n",
      "education_level           0\n",
      "major_discipline          0\n",
      "experience                0\n",
      "company_size              0\n",
      "company_type              0\n",
      "last_new_job              0\n",
      "training_hours            0\n",
      "target                    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1948\\4279898637.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[col].fillna(\"Unknown\", inplace=True)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1948\\4279898637.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[col].fillna(train[col].median(), inplace=True)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1948\\4279898637.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[col].fillna(train[col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill categorical missing values\n",
    "categorical_cols = [\"gender\", \"enrolled_university\", \"education_level\", \n",
    "                    \"major_discipline\", \"company_size\", \"company_type\"]\n",
    "for col in categorical_cols:\n",
    "    train[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Convert 'experience' and 'last_new_job' to numeric\n",
    "def convert_experience(x):\n",
    "    if x == \">20\":\n",
    "        return 21\n",
    "    elif x == \"<1\":\n",
    "        return 0\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "train[\"experience\"] = train[\"experience\"].apply(convert_experience)\n",
    "train[\"last_new_job\"] = train[\"last_new_job\"].apply(convert_experience)\n",
    "\n",
    "# Fill numeric missing values with median\n",
    "numeric_cols = [\"experience\", \"last_new_job\"]\n",
    "for col in numeric_cols:\n",
    "    train[col].fillna(train[col].median(), inplace=True)\n",
    "\n",
    "# Verify\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f49b7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in gender:\n",
      "gender\n",
      "Male       13221\n",
      "Unknown     4508\n",
      "Female      1238\n",
      "Other        191\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Unique values in enrolled_university:\n",
      "enrolled_university\n",
      "no_enrollment       13817\n",
      "Full time course     3757\n",
      "Part time course     1198\n",
      "Unknown               386\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Unique values in education_level:\n",
      "education_level\n",
      "Graduate          11598\n",
      "Masters            4361\n",
      "High School        2017\n",
      "Unknown             460\n",
      "Phd                 414\n",
      "Primary School      308\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Unique values in major_discipline:\n",
      "major_discipline\n",
      "STEM               14492\n",
      "Unknown             2813\n",
      "Humanities           669\n",
      "Other                381\n",
      "Business Degree      327\n",
      "Arts                 253\n",
      "No Major             223\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Unique values in company_size:\n",
      "company_size\n",
      "Unknown      5938\n",
      "50-99        3083\n",
      "100-500      2571\n",
      "10000+       2019\n",
      "10/49        1471\n",
      "1000-4999    1328\n",
      "<10          1308\n",
      "500-999       877\n",
      "5000-9999     563\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Unique values in company_type:\n",
      "company_type\n",
      "Pvt Ltd                9817\n",
      "Unknown                6140\n",
      "Funded Startup         1001\n",
      "Public Sector           955\n",
      "Early Stage Startup     603\n",
      "NGO                     521\n",
      "Other                   121\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Unique values in relevent_experience:\n",
      "relevent_experience\n",
      "Has relevent experience    13792\n",
      "No relevent experience      5366\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Unique values in city:\n",
      "city\n",
      "city_103    4355\n",
      "city_21     2702\n",
      "city_16     1533\n",
      "city_114    1336\n",
      "city_160     845\n",
      "            ... \n",
      "city_111       3\n",
      "city_129       3\n",
      "city_121       3\n",
      "city_140       1\n",
      "city_171       1\n",
      "Name: count, Length: 123, dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\"gender\", \"enrolled_university\", \"education_level\", \n",
    "                    \"major_discipline\", \"company_size\", \"company_type\", \"relevent_experience\", \"city\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"Unique values in {col}:\")\n",
    "    print(train[col].value_counts(dropna=False))\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d750b771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of exact duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicates = train.duplicated().sum()\n",
    "print(f\"Number of exact duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c9fdfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Columns\n",
    "# ---------------------------\n",
    "onehot_cols = [\"gender\", \"relevent_experience\", \"enrolled_university\", \"major_discipline\", \"company_type\"]\n",
    "ordinal_cols = [\"education_level\", \"company_size\"]\n",
    "\n",
    "# ---------------------------\n",
    "# One-Hot Encoding (Nominal columns)\n",
    "# ---------------------------\n",
    "train_encoded = pd.get_dummies(train, columns=onehot_cols, drop_first=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Ordinal Encoding (Columns with natural order)\n",
    "# ---------------------------\n",
    "education_order = [\"Primary School\", \"High School\", \"Graduate\", \"Masters\", \"Phd\"]\n",
    "train_encoded[\"education_level\"] = train[\"education_level\"].map({k: i for i, k in enumerate(education_order)})\n",
    "\n",
    "company_size_order = [\"Unknown\", \"<10\", \"10-49\", \"50-99\", \"100-499\", \"500-999\", \n",
    "                      \"1000-4999\", \"5000-9999\", \"10000+\"]\n",
    "train_encoded[\"company_size\"] = train[\"company_size\"].map({k: i for i, k in enumerate(company_size_order)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7806873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2129 entries, 0 to 2128\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             2129 non-null   int64  \n",
      " 1   city                    2129 non-null   object \n",
      " 2   city_development_index  2129 non-null   float64\n",
      " 3   gender                  1621 non-null   object \n",
      " 4   relevent_experience     2129 non-null   object \n",
      " 5   enrolled_university     2098 non-null   object \n",
      " 6   education_level         2077 non-null   object \n",
      " 7   major_discipline        1817 non-null   object \n",
      " 8   experience              2124 non-null   object \n",
      " 9   company_size            1507 non-null   object \n",
      " 10  company_type            1495 non-null   object \n",
      " 11  last_new_job            2089 non-null   object \n",
      " 12  training_hours          2129 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 216.4+ KB\n",
      "None\n",
      "27677\n"
     ]
    }
   ],
   "source": [
    "#aug_test.csv\n",
    "test = pd.read_csv(\"../data/aug_test.csv\")\n",
    "\n",
    "print(test.info())\n",
    "print(test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e44797f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enrollee_id                 0\n",
      "city                        0\n",
      "city_development_index      0\n",
      "gender                    508\n",
      "relevent_experience         0\n",
      "enrolled_university        31\n",
      "education_level            52\n",
      "major_discipline          312\n",
      "experience                  5\n",
      "company_size              622\n",
      "company_type              634\n",
      "last_new_job               40\n",
      "training_hours              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c4c7a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enrollee_id               0\n",
      "city                      0\n",
      "city_development_index    0\n",
      "gender                    0\n",
      "relevent_experience       0\n",
      "enrolled_university       0\n",
      "education_level           0\n",
      "major_discipline          0\n",
      "experience                0\n",
      "company_size              0\n",
      "company_type              0\n",
      "last_new_job              0\n",
      "training_hours            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1948\\3719866672.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[col].fillna(\"Unknown\", inplace=True)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1948\\3719866672.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[col].fillna(test[col].median(), inplace=True)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1948\\3719866672.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[col].fillna(test[col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill categorical missing values\n",
    "categorical_cols = [\"gender\", \"enrolled_university\", \"education_level\", \n",
    "                    \"major_discipline\", \"company_size\", \"company_type\"]\n",
    "for col in categorical_cols:\n",
    "    test[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Convert 'experience' and 'last_new_job' to numeric\n",
    "def convert_experience(x):\n",
    "    if x == \">20\":\n",
    "        return 21\n",
    "    elif x == \"<1\":\n",
    "        return 0\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "test[\"experience\"] = test[\"experience\"].apply(convert_experience)\n",
    "test[\"last_new_job\"] = test[\"last_new_job\"].apply(convert_experience)\n",
    "\n",
    "# Fill numeric missing values with median\n",
    "numeric_cols = [\"experience\", \"last_new_job\"]\n",
    "for col in numeric_cols:\n",
    "    test[col].fillna(test[col].median(), inplace=True)\n",
    "\n",
    "# Verify\n",
    "print(test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc8c80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Columns\n",
    "# ---------------------------\n",
    "onehot_cols = [\"gender\", \"relevent_experience\", \"enrolled_university\", \"major_discipline\", \"company_type\"]\n",
    "ordinal_cols = [\"education_level\", \"company_size\"]\n",
    "\n",
    "# ---------------------------\n",
    "# One-Hot Encoding (Nominal columns)\n",
    "# ---------------------------\n",
    "test_encoded = pd.get_dummies(test, columns=onehot_cols, drop_first=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Ordinal Encoding (Columns with natural order)\n",
    "# ---------------------------\n",
    "education_order = [\"Primary School\", \"High School\", \"Graduate\", \"Masters\", \"Phd\"]\n",
    "test_encoded[\"education_level\"] = test[\"education_level\"].map({k: i for i, k in enumerate(education_order)})\n",
    "\n",
    "company_size_order = [\"Unknown\", \"<10\", \"10-49\", \"50-99\", \"100-499\", \"500-999\", \n",
    "                      \"1000-4999\", \"5000-9999\", \"10000+\"]\n",
    "test_encoded[\"company_size\"] = test[\"company_size\"].map({k: i for i, k in enumerate(company_size_order)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e042c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance (Validation Set)\n",
      "Accuracy : 0.7716597077244259\n",
      "Precision: 0.5854700854700855\n",
      "Recall   : 0.2869109947643979\n",
      "F1 Score : 0.38510189739985945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# LOGISTIC REGRESSION (BASELINE)\n",
    "# ============================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ----------------------------\n",
    "# Feature / Target split\n",
    "# ----------------------------\n",
    "X = train_encoded.drop([\"target\", \"enrollee_id\", \"city\"], axis=1)\n",
    "y = train_encoded[\"target\"]\n",
    "\n",
    "# Align test columns (DO NOT generate predictions yet)\n",
    "X_test = test_encoded.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "X_test = X_test.fillna(X.median())  # avoid leakage\n",
    "\n",
    "# ----------------------------\n",
    "# Train / Validation split\n",
    "# ----------------------------\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Train Logistic Regression\n",
    "# ----------------------------\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_model.fit(X_tr, y_tr)\n",
    "\n",
    "# ----------------------------\n",
    "# Validation predictions\n",
    "# ----------------------------\n",
    "log_val_preds = log_model.predict(X_val)\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluation (THIS is what matters now)\n",
    "# ----------------------------\n",
    "print(\"Logistic Regression Performance (Validation Set)\")\n",
    "print(\"Accuracy :\", accuracy_score(y_val, log_val_preds))\n",
    "print(\"Precision:\", precision_score(y_val, log_val_preds))\n",
    "print(\"Recall   :\", recall_score(y_val, log_val_preds))\n",
    "print(\"F1 Score :\", f1_score(y_val, log_val_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ebbd6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance (Validation Set)\n",
      "Accuracy : 0.7794885177453027\n",
      "Precision: 0.5654761904761905\n",
      "Recall   : 0.4973821989528796\n",
      "F1 Score : 0.5292479108635098\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# MODEL 2: RANDOM FOREST\n",
    "# ============================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_tr, y_tr)\n",
    "\n",
    "rf_val_preds = rf_model.predict(X_val)\n",
    "\n",
    "print(\"Random Forest Performance (Validation Set)\")\n",
    "print(\"Accuracy :\", accuracy_score(y_val, rf_val_preds))\n",
    "print(\"Precision:\", precision_score(y_val, rf_val_preds))\n",
    "print(\"Recall   :\", recall_score(y_val, rf_val_preds))\n",
    "print(\"F1 Score :\", f1_score(y_val, rf_val_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa6683d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Performance (Validation Set)\n",
      "Accuracy : 0.7969728601252609\n",
      "Precision: 0.5954692556634305\n",
      "Recall   : 0.5780104712041885\n",
      "F1 Score : 0.5866099893730075\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# MODEL 3: XGBOOST\n",
    "# ============================\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train on training split\n",
    "xgb_model.fit(X_tr, y_tr)\n",
    "\n",
    "# Validation predictions\n",
    "xgb_val_preds = xgb_model.predict(X_val)\n",
    "\n",
    "# Evaluation\n",
    "print(\"XGBoost Performance (Validation Set)\")\n",
    "print(\"Accuracy :\", accuracy_score(y_val, xgb_val_preds))\n",
    "print(\"Precision:\", precision_score(y_val, xgb_val_preds))\n",
    "print(\"Recall   :\", recall_score(y_val, xgb_val_preds))\n",
    "print(\"F1 Score :\", f1_score(y_val, xgb_val_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81efda8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final predictions saved to outputs/final_predictions.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id  prediction\n",
       "0        32403           0\n",
       "1         9858           0\n",
       "2        31806           0\n",
       "3        27385           0\n",
       "4        27724           0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# FINAL MODEL (XGBOOST)\n",
    "# ============================\n",
    "\n",
    "# Retrain XGBoost on FULL training data\n",
    "best_model = xgb_model\n",
    "best_model.fit(X, y)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# GENERATE FINAL PREDICTIONS\n",
    "# ============================\n",
    "\n",
    "final_test_preds = best_model.predict(X_test)\n",
    "\n",
    "final_predictions = pd.DataFrame({\n",
    "    \"enrollee_id\": test[\"enrollee_id\"],\n",
    "    \"prediction\": final_test_preds\n",
    "})\n",
    "\n",
    "\n",
    "# ============================\n",
    "# SAVE OUTPUT\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "final_predictions.to_csv(\"outputs/final_predictions.csv\", index=False)\n",
    "\n",
    "print(\"✅ Final predictions saved to outputs/final_predictions.csv\")\n",
    "final_predictions.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
